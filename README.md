![CI](https://github.com/DagueG/Model_Machine_Learning/actions/workflows/ci.yml/badge.svg)

# Futurisys ML Deploy üöÄ

Une API FastAPI pour le d√©ploiement et la pr√©diction d'un mod√®le de Machine Learning capable de pr√©dire la consommation √©nerg√©tique des b√¢timents.

## üìã Objectif
D√©ployer un mod√®le de ML (Random Forest) derri√®re une API FastAPI pour fournir des pr√©dictions en temps r√©el sur la consommation √©nerg√©tique des propri√©t√©s.
---

## üìÅ Structure du Projet

```
Model_Machine_Learning/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # Application FastAPI principale avec tous les endpoints
‚îÇ   ‚îú‚îÄ‚îÄ models.py               # Mod√®les SQLAlchemy pour la base de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ p3_request.py       # Mod√®les Pydantic pour la validation des requ√™tes
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ p3_model.py         # Classe de service pour charger et utiliser le mod√®le ML
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py         # Configuration SQLAlchemy et session management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ model_p3.joblib         # Mod√®le ML s√©rialis√© (Random Forest)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_health.py      # Tests unitaires pour l'endpoint /health
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_p3_predict.py  # Tests d'int√©gration pour l'endpoint /predict et DB
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/
‚îú‚îÄ‚îÄ docker-compose.yml          # Configuration PostgreSQL avec Docker
‚îú‚îÄ‚îÄ create_db.py                # Script d'initialisation de la base de donn√©es
‚îú‚îÄ‚îÄ .env                        # Variables d'environnement (local)
‚îú‚îÄ‚îÄ .env.example                # Template des variables d'environnement
‚îú‚îÄ‚îÄ pyproject.toml              # Configuration du projet et d√©pendances
‚îî‚îÄ‚îÄ README.md                   # Documentation du projet
```

---

## üõ†Ô∏è Installation

### Pr√©requis
- Python >= 3.11
- [uv](https://docs.astral.sh/uv/) (gestionnaire de paquets Python)
- Docker & Docker Compose (pour PostgreSQL)

### √âtapes d'installation

```bash
# 1. Initialiser l'environnement virtuel avec Python 3.11
uv init --python 3.11

# 2. Installer toutes les d√©pendances du projet
uv sync

# 3. Copier le fichier .env
cp .env.example .env

# 4. D√©marrer PostgreSQL avec Docker
docker-compose up -d

# 5. Initialiser la base de donn√©es
uv run python create_db.py
```

### V√©rification du statut PostgreSQL
```bash
docker-compose ps
```

### Arr√™ter PostgreSQL
```bash
docker-compose down
```

---

## üöÄ Lancer le Projet Localement

### D√©marrer le serveur FastAPI
```bash
uv run uvicorn app.main:app --reload
```

Le serveur sera accessible sur `http://localhost:8000`

### Acc√®s √† la documentation interactive
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## üì° Endpoints disponibles

### 1. **V√©rification de sant√©**
```http
GET /health
```

**R√©ponse r√©ussie (200)**:
```json
{
  "status": "ok",
  "message": "API en ligne üöÄ"
}
```

---

### 2. **Pr√©diction de consommation √©nerg√©tique**
```http
POST /api/p3/predict
```

**Payload (application/json)**:
```json
{
  "BuildingType": "Commercial",
  "PrimaryPropertyType": "Office",
  "ZipCode": 98101,
  "CouncilDistrictCode": 1,
  "Neighborhood": "Downtown",
  "Latitude": 47.6062,
  "Longitude": -122.3321,
  "YearBuilt": 2005,
  "NumberofBuildings": 1,
  "NumberofFloors": 10,
  "PropertyGFATotal": 50000.0,
  "PropertyGFAParking": 5000.0,
  "PropertyGFABuildings": 45000.0,
  "ListOfAllPropertyUseTypes": "Office",
  "LargestPropertyUseType": "Office",
  "LargestPropertyUseTypeGFA": 45000.0,
  "SecondLargestPropertyUseType": null,
  "SecondLargestPropertyUseTypeGFA": null,
  "ThirdLargestPropertyUseType": null,
  "ThirdLargestPropertyUseTypeGFA": null,
  "YearsENERGYSTARCertified": 5,
  "Outlier": "No",
  "BuildingAge": 19.0,
  "SurfacePerFloor": 4500.0,
  "IsMultiUse": false,
  "LatZone": 47,
  "LonZone": 122
}
```

**R√©ponse r√©ussie (200)**:
```json
{
  "prediction": 1250.5
}
```

---

### 3. **R√©cup√©rer l'historique des pr√©dictions**
```http
GET /api/p3/history?skip=0&limit=100
```

**Param√®tres de query**:
- `skip` (optional): Nombre d'enregistrements √† ignorer (d√©faut: 0)
- `limit` (optional): Nombre maximal d'enregistrements √† retourner (d√©faut: 100)

**R√©ponse r√©ussie (200)**:
```json
{
  "total": 42,
  "predictions": [
    {
      "id": 1,
      "prediction": 1250.5,
      "building_type": "Commercial",
      "created_at": "2025-12-10T12:30:45.123456"
    },
    ...
  ]
}
```

---

### 4. **R√©cup√©rer une pr√©diction sp√©cifique**
```http
GET /api/p3/prediction/{prediction_id}
```

**R√©ponse r√©ussie (200)**:
```json
{
  "id": 1,
  "prediction": 1250.5,
  "building_type": "Commercial",
  "created_at": "2025-12-10T12:30:45.123456"
}
```

---

## üóÑÔ∏è Base de Donn√©es

### Architecture

La base de donn√©es PostgreSQL enregistre **automatiquement** toutes les entr√©es et sorties du mod√®le ML.

#### Table: `energy_predictions`

| Colonne | Type | Description |
|---------|------|-------------|
| `id` | INTEGER | Cl√© primaire auto-incr√©ment√©e |
| `building_type` | VARCHAR | Type de b√¢timent |
| `primary_property_type` | VARCHAR | Type de propri√©t√© principal |
| `zip_code` | INTEGER | Code postal |
| `council_district_code` | INTEGER | Code district conseil |
| `neighborhood` | VARCHAR | Quartier |
| `latitude` | FLOAT | Latitude GPS |
| `longitude` | FLOAT | Longitude GPS |
| `year_built` | INTEGER | Ann√©e de construction |
| `number_of_buildings` | INTEGER | Nombre de b√¢timents |
| `number_of_floors` | INTEGER | Nombre d'√©tages |
| `property_gfa_total` | FLOAT | Surface GFA totale |
| `property_gfa_parking` | FLOAT | Surface parking GFA |
| `property_gfa_buildings` | FLOAT | Surface b√¢timents GFA |
| ... | ... | *25+ champs d'entr√©e* |
| `prediction` | FLOAT | **R√©sultat de la pr√©diction** |
| `created_at` | TIMESTAMP | Date/heure de cr√©ation |

### Sch√©ma UML Simplifi√©

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   EnergyPrediction      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)                 ‚îÇ
‚îÇ building_type           ‚îÇ
‚îÇ primary_property_type   ‚îÇ
‚îÇ zip_code                ‚îÇ
‚îÇ council_district_code   ‚îÇ
‚îÇ neighborhood            ‚îÇ
‚îÇ latitude                ‚îÇ
‚îÇ longitude               ‚îÇ
‚îÇ ... (25+ input fields)  ‚îÇ
‚îÇ prediction (OUTPUT) ‚≠ê   ‚îÇ
‚îÇ created_at (TIMESTAMP)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Gestion de la base de donn√©es

**Cr√©er les tables** (automatique au premier d√©marrage):
```bash
uv run python create_db.py
```

**R√©initialiser la base de donn√©es** (‚ö†Ô∏è supprime toutes les donn√©es):
```bash
uv run python create_db.py drop
```

**Interroger les donn√©es directement**:
```python
from app.core.database import SessionLocal
from app.models import EnergyPrediction

db = SessionLocal()
predictions = db.query(EnergyPrediction).all()
for pred in predictions:
    print(f"ID: {pred.id}, Pr√©diction: {pred.prediction}, Date: {pred.created_at}")
db.close()
```

---

## üîß Architecture et Composants

### `app/main.py`
- **R√¥le**: Point d'entr√©e principal de l'application
- **Contient**: 
  - Configuration de l'application FastAPI
  - Tous les endpoints de l'API
  - Logique de pr√©diction et enregistrement en DB
  - Endpoints de consultation de l'historique

### `app/models.py`
- **R√¥le**: Mod√®les SQLAlchemy pour la persistance
- **Contient**: 
  - `EnergyPrediction`: Mod√®le ORM repr√©sentant la table `energy_predictions`
  - Tous les champs d'entr√©e du ML + r√©sultat de pr√©diction

### `app/core/database.py`
- **R√¥le**: Configuration de la base de donn√©es
- **Contient**: 
  - Configuration SQLAlchemy + psycopg3
  - SessionLocal factory
  - D√©pendance `get_db()` pour l'injection dans les endpoints

### `app/schemas/p3_request.py`
- **R√¥le**: D√©finition des mod√®les de donn√©es
- **Contient**: 
  - `EnergyRequest`: Mod√®le Pydantic pour valider les requ√™tes de pr√©diction
  - `PredictionResponse`: Mod√®le de r√©ponse pour une pr√©diction unique
  - `PredictionHistoryResponse`: Mod√®le de r√©ponse pour l'historique
  - 25+ champs pour d√©crire les caract√©ristiques d'un b√¢timent

### `app/services/p3_model.py`
- **R√¥le**: Service de gestion du mod√®le ML
- **Contient**: 
  - `EnergyModel`: Classe singleton pour charger et utiliser le mod√®le
  - Gestion du cache du mod√®le (charg√© une seule fois en m√©moire)
  - M√©thode `predict()` pour g√©n√©rer des pr√©dictions

### `models/model_p3.joblib`
- **Format**: Fichier binaire s√©rialis√© (joblib)
- **Contenu**: Mod√®le Random Forest entra√Æn√©
- **Utilisation**: Charg√© au moment de la premi√®re requ√™te

### `docker-compose.yml`
- **R√¥le**: Configuration de PostgreSQL en conteneur
- **Contient**: 
  - Service PostgreSQL 16 Alpine
  - Configuration des credentials
  - Volumes persistants pour les donn√©es
  - Health check automatique

### `create_db.py`
- **R√¥le**: Script d'initialisation de la base de donn√©es
- **Utilisation**: 
  - `uv run python create_db.py` ‚Üí Cr√©e les tables
  - `uv run python create_db.py drop` ‚Üí Supprime les tables

---

## üß™ Tests

### Ex√©cuter tous les tests
```bash
uv run pytest
```

### Tests unitaires
```bash
uv run pytest tests/unit/
```

### Tests d'int√©gration
```bash
uv run pytest tests/integration/
```

### Tests avec couverture de code
```bash
uv run pytest --cov=app --cov-report=html
```

---

## üì¶ D√©pendances principales

| Paquet | Version | Utilit√© |
|--------|---------|---------|
| `fastapi` | >=0.119.1 | Framework API web |
| `uvicorn` | >=0.38.0 | Serveur ASGI |
| `pydantic` | >=2.12.3 | Validation des donn√©es |
| `pandas` | >=2.3.3 | Manipulation des donn√©es |
| `scikit-learn` | >=1.7.2 | Mod√®le ML et utilitaires |
| `joblib` | >=1.5.2 | S√©rialisation du mod√®le |
| `pytest` | >=8.4.2 | Framework de test |
| `pytest-cov` | >=7.0.0 | Couverture de tests |
| `sqlalchemy` | >=2.0.44 | ORM pour la base de donn√©es |
| `psycopg[binary]` | >=3.2.11 | Driver PostgreSQL Python |
| `python-dotenv` | >=1.1.1 | Gestion des variables d'environnement |

---

## üìù Conventions de Commit

Pour maintenir un historique de commits clair et coh√©rent :

| Type | Description | Exemple |
|------|-------------|---------|
| **ADD** | Ajout de fonctionnalit√©/fichier | `ADD: endpoint de pr√©diction` |
| **FIX** | Correction de bug/probl√®me | `FIX: erreur de validation` |
| **DOCS** | Documentation | `DOCS: mise √† jour du README` |
| **DEL** | Suppression volontaire | `DEL: route obsol√®te` |

---

## üîê Variables d'environnement

Si n√©cessaire, cr√©ez un fichier `.env` √† la racine du projet :

```bash
# Exemple de configuration
API_TITLE=Futurisys ML API
API_VERSION=0.1.0
LOG_LEVEL=INFO
```

---

## üìä Flux de Pr√©diction

```
Requ√™te HTTP POST /api/p3/predict
    ‚Üì
Validation Pydantic (EnergyRequest)
    ‚Üì
Renommage du champ PropertyGFABuildings
    ‚Üì
Conversion en DataFrame pandas
    ‚Üì
Chargement du mod√®le (singleton)
    ‚Üì
Pr√©diction ML
    ‚Üì
Enregistrement en base de donn√©es PostgreSQL ‚≠ê
    ‚Üì
R√©ponse JSON {"prediction": value}
```

### Enregistrement des donn√©es

Chaque pr√©diction est automatiquement enregistr√©e dans la table `energy_predictions` avec:
- ‚úÖ Tous les champs d'entr√©e
- ‚úÖ Le r√©sultat de la pr√©diction
- ‚úÖ L'horodatage exact (UTC)

---

## üöÄ D√©ploiement

### D√©ploiement sur Hugging Face Spaces

Cette application est pr√™te √† √™tre d√©ploy√©e sur [Hugging Face Spaces](https://huggingface.co/spaces).

#### √âtapes:

1. **Cr√©er un nouvel Space sur Hugging Face**
   - Aller sur https://huggingface.co/new-space
   - S√©lectionner **Docker** comme runtime
   - Nommer l'espace: `model-machine-learning`
   - Rendre public ou priv√© selon vos besoins

2. **Connecter votre d√©p√¥t GitHub**
   - Dans les param√®tres du Space, activer la synchronisation GitHub
   - S√©lectionner votre d√©p√¥t `Model_Machine_Learning`
   - S√©lectionner la branche `main`

3. **Configuration automatique**
   - HF Spaces d√©tectera automatiquement le `Dockerfile`
   - Construira et d√©ploiera l'image Docker
   - L'API sera accessible via `https://huggingface.co/spaces/[username]/model-machine-learning`

#### Variables d'environnement

Laissez `DATABASE_URL` vide pour utiliser SQLite automatiquement sur HF Spaces:

```
# Database: Auto-switch
# - Si DATABASE_URL vide ‚Üí SQLite (HF Spaces)
# - Si DATABASE_URL d√©fini ‚Üí PostgreSQL (local)
```

#### Points importants:

- ‚úÖ **Base de donn√©es**: SQLite (`/tmp/predictions.db`) - pas besoin de PostgreSQL sur HF
- ‚úÖ **Port**: 7860 (standard HF Spaces)
- ‚úÖ **Documentation**: Swagger UI accessible √† `/docs`
- ‚ö†Ô∏è **Donn√©es persistantes**: Les pr√©dictions sont sauvegard√©es tant que le Space tourne

### D√©ploiement local avec Docker

```bash
# Builder l'image Docker
docker build -t model-api .

# Lancer le conteneur
docker run -p 8000:7860 model-api
```

### Autres options de d√©ploiement

Pour un d√©ploiement en production:

1. **Conteneurisation**: Docker ‚úÖ (configur√©)
2. **Orchestration**: Kubernetes
3. **CI/CD**: GitHub Actions (configur√© dans `.github/workflows/`)
4. **Monitoring**: Application Performance Monitoring (APM)
5. **Base de donn√©es persistante**: PostgreSQL (remplacer DATABASE_URL)

---

## üìÑ Licence

Projet r√©alis√© dans le cadre d'OpenClassroom.

---

## üë§ Auteur

**DagueG** - [GitHub Profile](https://github.com/DagueG)
